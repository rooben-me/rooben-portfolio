---
date: "2023-5-19"
thumbnail: "/image/work/stable-diffusion/thumbnail.webp"
thumbnailBanner: "/image/work/stable-diffusion/banner.webp"
title: "Stable diffusion"
roles: ["research"]
description: "A Journey towards Latent space"
draft: true
---

## Code Explanation

Let's dive into the code!

1. First, I imported the necessary libraries and set the plotting style to 'fivethirtyeight'.

```python
import os
import numpy as np
import pandas as pd
from keras.optimizers import SGD
from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout, GRU, SimpleRNN
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
```

2. In the `create_files_dict` function, I read the CSV files containing the order data and stored them in a dictionary with the file_key as the key and the data as the value.

```python
def create_files_dict(pth='/content/order'):
    files = os.listdir(pth)
    all_data = dict()

    for file in files:
        file_key = file.split('_')[0]
        file_path = os.path.join(pth, file)
        data = pd.read_csv(file_path, index_col='Date', parse_dates=['Date'])
        all_data[file_key] = data

    return all_data
```

3. The `plot_data` function helps me visualize the training and test sets.

```python
def plot_data(data, market_name):
    data["count"][:'2022'].plot(figsize=(16, 4), legend=True)
    data["count"]['2023':].plot(figsize=(16, 4), legend=True)
    plt.legend(['Training set (Before 2022)', 'Test set (2022 and beyond)'])
    plt.title('{} Orders'.format(market_name))
    plt.pause(1)
    plt.close()
```

4. In the `create_dl_train_test_split` function, I split the data into training and test sets, scaled the training set using MinMaxScaler, and prepared the input data for the deep learning models.

```python
def create_dl_train_test_split(all_data):
    training_set = all_data.loc[:'2022', 'count'].values
    test_set = all_data.loc['2023':, 'count'].values
    sc = MinMaxScaler(feature_range=(0, 1))
    training_set_scaled = sc.fit_transform(training_set.reshape(-1, 1))

    X_train, y_train = [], []
    for i in range(60, len(training_set_scaled)):
        X_train.append(training_set_scaled[i - 60:i, 0])
        y_train.append(training_set_scaled[i, 0])

    X_train, y_train = np.array(X_train), np.array(y_train)
    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

    total_data = pd.concat((all_data["count"][:'2022'], all_data["count"]['2023':]), axis=0)
    inputs = total_data[len(total_data) - len(test_set) - 60:].values
    inputs = inputs.reshape(-1, 1)
    inputs = sc.transform(inputs)

    X_test = []
    for i in range(60, len(inputs)):
        X_test.append(inputs[i - 60:i, 0])

    X_test = np.array(X_test)
    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

    return X_train, y_train, X_test, sc

```

5. I created various deep learning models using Keras, including a single-layer small RNN (`create_single_layer_small_rnn_model`), a single-layer RNN (`create_single_layer_rnn_model`), a multi-layer RNN (`create_rnn_model`), a GRU model (`create_GRU_model`), and a GRU model with dropout (`create_GRU_with_drop_out_model`).

```python
def create_single_layer_small_rnn_model(X_train, y_train, X_test, sc):
    model = Sequential()
    model.add(SimpleRNN(6))
    model.add(Dense(1))
    model.compile(optimizer='rmsprop', loss='mean_squared_error')
    model.fit(X_train, y_train, epochs=100, batch_size=150)
    scaled_preds = model.predict(X_test)
    test_preds = sc.inverse_transform(scaled_preds)

    return model, test_preds


def create_single_layer_rnn_model(X_train, y_train, X_test, sc):
    model = Sequential()
    model.add(SimpleRNN(32))
    model.add(Dense(1))
    model.compile(optimizer='rmsprop', loss='mean_squared_error')
    model.fit(X_train, y_train, epochs=100, batch_size=150)
    scaled_preds = model.predict(X_test)
    test_preds = sc.inverse_transform(scaled_preds)

    return model, test_preds


def create_rnn_model(X_train, y_train, X_test, sc):
    model = Sequential()
    model.add(SimpleRNN(32, return_sequences=True))
    model.add(SimpleRNN(32, return_sequences=True))
    model.add(SimpleRNN(32, return_sequences=True))
    model.add(SimpleRNN(32))
    model.add(Dense(1))
    model.compile(optimizer='rmsprop', loss='mean_squared_error')
    model.fit(X_train, y_train, epochs=100, batch_size=150)
    scaled_preds = model.predict(X_test)
    test_preds = sc.inverse_transform(scaled_preds)

    return model, test_preds


def create_GRU_model(X_train, y_train, X_test, sc):
    regressorGRU = Sequential()
    regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1), activation='tanh'))
    regressorGRU.add(GRU(units=50, return_sequences=True, activation='tanh'))
    regressorGRU.add(GRU(units=50, return_sequences=True, activation='tanh'))
    regressorGRU.add(GRU(units=50, activation='tanh'))
    regressorGRU.add(Dense(units=1))
    regressorGRU.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False), loss='mean_squared_error')
    regressorGRU.fit(X_train, y_train, epochs=50, batch_size=150)
    GRU_predicted_market_order = regressorGRU.predict(X_test)
    GRU_predicted_market_order = sc.inverse_transform(GRU_predicted_market_order)

    return regressorGRU, GRU_predicted_market_order


def create_GRU_with_drop_out_model(X_train, y_train, X_test, sc):
    regressorGRU = Sequential()
    regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1), activation='tanh'))
    regressorGRU.add(Dropout(0.2))
    regressorGRU.add(GRU(units=50, return_sequences=True, activation='tanh'))
    regressorGRU.add(Dropout(0.2))
    regressorGRU.add(GRU(units=50, return_sequences=True, activation='tanh'))
    regressorGRU.add(Dropout(0.2))
    regressorGRU.add(GRU(units=50, activation='tanh'))
    regressorGRU.add(Dropout(0.2))
    regressorGRU.add(Dense(units=1))
    regressorGRU.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False), loss='mean_squared_error')
    regressorGRU.fit(X_train, y_train, epochs=50, batch_size=150)
    GRU_predicted_market_order = regressorGRU.predict(X_test)
    GRU_predicted_market_order = sc.inverse_transform(GRU_predicted_market_order)

    return regressorGRU, GRU_predicted_market_order
```

6. The `plot_full_data_with_predictions` function plots the full dataset along with the predictions made by each model.

```python
def plot_full_data_with_predictions(actuals, market_name, small_one_layer_preds, one_layer_preds, gru_drop_preds, rnn_preds, gru_preds):
    plt.figure(figsize=(20, 10))

    models = [
        ('Single Layer Small RNN', small_one_layer_preds),
        ('Single Layer RNN', one_layer_preds),
        ('GRU with dropout', gru_drop_preds),
        ('RNN', rnn_preds),
        ('GRU', gru_preds)
    ]

    actual_values = actuals['2023':].values[:-1]

    plt.plot(actuals.values, label='Full dataset')

    for model_name, preds in models:
        preds = preds[:len(actual_values)]  # Ensure the length of predictions is the same as actual_values
        plt.plot(range(len(actuals) - len(actual_values), len(actuals)), preds, label=model_name + ' predictions')

    plt.title('{} Full Dataset with AI Predictions'.format(market_name))
    plt.legend()
    plt.pause(1)
    plt.close()

```

7. In the `plot_results` function, I plotted the actual values against the predictions made by each model and calculated the Mean Squared Error (MSE) for each model.

```python
def plot_results(actuals, market_name, small_one_layer_preds, one_layer_preds, gru_drop_preds, rnn_preds, gru_preds):
    fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(30, 15))
    axes = axes.ravel()

    models = [
        ('Single Layer Small RNN', small_one_layer_preds),
        ('Single Layer RNN', one_layer_preds),
        ('GRU with dropout', gru_drop_preds),
        ('RNN', rnn_preds),
        ('GRU', gru_preds)
    ]

    mse_results = []

    actual_values = actuals['2023':].values[:-1]

    for i, (model_name, preds) in enumerate(models):
        preds = preds[:len(actual_values)]  # Ensure the length of predictions is the same as actual_values
        axes[i].plot(actual_values, label='Actual values')
        axes[i].plot(preds, label=model_name + ' predictions')
        axes[i].set_title('{} Predictions vs. Actual'.format(model_name))
        axes[i].legend()

        mse = mean_squared_error(actual_values, preds)
        mse_results.append((model_name, mse))

    plt.tight_layout()
    plt.pause(1)
    plt.close()

    mse_df = pd.DataFrame(mse_results, columns=['Model', 'MSE'])
    mse_df.sort_values(by='MSE', ascending=True, inplace=True)
    print("Mean Squared Error (MSE) for each model:")
    print(mse_df)

```

8. Finally, in the `main` section of the code, I looped through each method, prepared the data, trained the models, and visualized the results.

```python
if __name__ == '__main__':
    all_data = create_files_dict()
    for market_name, market_data in all_data.items():

        X_train, y_train, X_test, sc = create_dl_train_test_split(market_data)

        small_single_layer_rnn, small_one_layer_preds = create_single_layer_small_rnn_model(X_train, y_train, X_test, sc)
        single_layer_rnn, one_layer_preds = create_single_layer_rnn_model(X_train, y_train, X_test, sc)
        rnn_model, rnn_preds = create_rnn_model(X_train, y_train, X_test, sc)
        gru_model, gru_preds = create_GRU_model(X_train, y_train, X_test, sc)
        gru_drop_model, gru_drop_preds = create_GRU_with_drop_out_model(X_train, y_train, X_test, sc)

        plot_data(market_data, market_name)
        plot_results(market_data, market_name, small_one_layer_preds, one_layer_preds, gru_drop_preds, rnn_preds, gru_preds)
        plot_full_data_with_predictions(market_data, market_name, small_one_layer_preds, one_layer_preds, gru_drop_preds, rnn_preds, gru_preds)
```
